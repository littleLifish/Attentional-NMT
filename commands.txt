train the model:
python train.py --data data-bin/iwslt14.tokenized.de-en/ --optimizer Adam --learning_rate 1e-3 --model_file checkpoints/iwlst14/ --gpuid 0

generate translation:
python generate.py --data data-bin/iwslt14.tokenized.de-en/ --batch-size 128 --model_file checkpoints/iwlst14/best_gmodel.pt --gpuid 0 --remove-bpe --beam 5

compute BLEU scores:
perl scripts/multi-bleu.perl < ground_truth.txt translation.txt